# üèóÔ∏è Architecture Decision Records (ADRs) - Grok-Beast Trading Bot

## üìã Tabla de Contenidos

1. [ADR-001: Elecci√≥n de FastAPI como Framework Principal](#adr-001-elecci√≥n-de-fastapi-como-framework-principal)
2. [ADR-002: Implementaci√≥n de Microservicios vs Monolito](#adr-002-implementaci√≥n-de-microservicios-vs-monolito)
3. [ADR-003: Estrategia de Base de Datos](#adr-003-estrategia-de-base-de-datos)
4. [ADR-004: Sistema de Cache con Redis](#adr-004-sistema-de-cache-con-redis)
5. [ADR-005: Arquitectura de An√°lisis T√©cnico](#adr-005-arquitectura-de-an√°lisis-t√©cnico)
6. [ADR-006: Integraci√≥n de IA con Ollama](#adr-006-integraci√≥n-de-ia-con-ollama)
7. [ADR-007: Gesti√≥n de Riesgo Multi-Nivel](#adr-007-gesti√≥n-de-riesgo-multi-nivel)
8. [ADR-008: Sistema de Monitoreo y Alertas](#adr-008-sistema-de-monitoreo-y-alertas)
9. [ADR-009: Estrategia de Testing](#adr-009-estrategia-de-testing)
10. [ADR-010: Pipeline de CI/CD](#adr-010-pipeline-de-cicd)

---

## ADR-001: Elecci√≥n de FastAPI como Framework Principal

**Fecha**: 2024-01-15  
**Estado**: Aceptado  
**Decisor**: Equipo de Desarrollo  

### Contexto
Necesitamos elegir un framework web para el backend del trading bot que sea:
- R√°pido y eficiente
- Soporte async/await nativo
- Documentaci√≥n autom√°tica de APIs
- Validaci√≥n de datos robusta
- F√°cil de mantener y escalar

### Opciones Consideradas

#### 1. Django + Django REST Framework
**Pros:**
- Framework maduro y estable
- ORM potente
- Admin interface incluido
- Gran ecosistema

**Contras:**
- M√°s pesado para APIs simples
- Menos eficiente para operaciones async
- Curva de aprendizaje m√°s pronunciada

#### 2. Flask + Flask-RESTful
**Pros:**
- Muy ligero y flexible
- F√°cil de personalizar
- Gran control sobre la implementaci√≥n

**Contras:**
- Requiere m√°s configuraci√≥n manual
- No tiene validaci√≥n autom√°tica
- Menos soporte para async

#### 3. FastAPI
**Pros:**
- Muy r√°pido (similar a Node.js y Go)
- Soporte nativo async/await
- Documentaci√≥n autom√°tica con OpenAPI/Swagger
- Validaci√≥n autom√°tica con Pydantic
- Type hints nativos
- Excelente para APIs modernas

**Contras:**
- Framework m√°s nuevo (menos maduro)
- Menor ecosistema que Django

### Decisi√≥n
**Elegimos FastAPI** como framework principal.

### Consecuencias

#### Positivas:
- ‚úÖ APIs r√°pidas y eficientes
- ‚úÖ Documentaci√≥n autom√°tica
- ‚úÖ Validaci√≥n robusta de datos
- ‚úÖ Soporte nativo async/await
- ‚úÖ Type hints para mejor mantenibilidad

#### Negativas:
- ‚ö†Ô∏è Curva de aprendizaje para el equipo
- ‚ö†Ô∏è Menor ecosistema de plugins
- ‚ö†Ô∏è Menos recursos de aprendizaje disponibles

### Implementaci√≥n
```python
# Ejemplo de endpoint FastAPI
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI(title="Grok-Beast Trading API", version="2.0.0")

class TradingRequest(BaseModel):
    symbol: str
    side: str
    quantity: float

@app.post("/api/trading/orders")
async def create_order(request: TradingRequest):
    # Validaci√≥n autom√°tica con Pydantic
    # Documentaci√≥n autom√°tica
    return {"order_id": "123", "status": "pending"}
```

---

## ADR-002: Implementaci√≥n de Microservicios vs Monolito

**Fecha**: 2024-01-15  
**Estado**: Aceptado  
**Decisor**: Equipo de Arquitectura  

### Contexto
Debemos decidir entre una arquitectura monol√≠tica o de microservicios para el trading bot, considerando:
- Complejidad del sistema
- Equipo de desarrollo
- Requisitos de escalabilidad
- Tiempo de desarrollo

### Opciones Consideradas

#### 1. Monolito Modular
**Pros:**
- Desarrollo m√°s r√°pido
- Debugging m√°s f√°cil
- Transacciones ACID simples
- Menos complejidad operacional

**Contras:**
- Escalabilidad limitada
- Dependencias acopladas
- Deployment de todo el sistema

#### 2. Microservicios
**Pros:**
- Escalabilidad independiente
- Tecnolog√≠as heterog√©neas
- Deployment independiente
- Equipos independientes

**Contras:**
- Complejidad operacional alta
- Network latency
- Distributed transactions
- Debugging complejo

### Decisi√≥n
**Elegimos Monolito Modular** para la fase inicial.

### Justificaci√≥n
1. **Equipo peque√±o**: 3-5 desarrolladores
2. **Time to market**: Necesitamos lanzar r√°pido
3. **Complejidad**: El sistema es complejo pero no requiere escalabilidad masiva inicialmente
4. **Transacciones**: Trading requiere consistencia ACID

### Arquitectura Propuesta
```
grok-beast/
‚îú‚îÄ‚îÄ core/           # L√≥gica de negocio central
‚îú‚îÄ‚îÄ trading/        # M√≥dulo de trading
‚îú‚îÄ‚îÄ analysis/       # An√°lisis t√©cnico
‚îú‚îÄ‚îÄ ai/            # IA y autopilot
‚îú‚îÄ‚îÄ risk/          # Gesti√≥n de riesgo
‚îú‚îÄ‚îÄ monitoring/    # Monitoreo y alertas
‚îî‚îÄ‚îÄ api/           # APIs REST
```

### Migraci√≥n Futura
Planificamos migrar a microservicios en la Fase 3:
- **Trading Service**: √ìrdenes y ejecuci√≥n
- **Analysis Service**: An√°lisis t√©cnico
- **AI Service**: IA y autopilot
- **Risk Service**: Gesti√≥n de riesgo
- **Notification Service**: Alertas y notificaciones

---

## ADR-003: Estrategia de Base de Datos

**Fecha**: 2024-01-15  
**Estado**: Aceptado  
**Decisor**: Equipo de Backend  

### Contexto
Necesitamos elegir una estrategia de base de datos que soporte:
- Datos de trading en tiempo real
- An√°lisis t√©cnico hist√≥rico
- M√©tricas y logs
- Escalabilidad futura

### Opciones Consideradas

#### 1. PostgreSQL
**Pros:**
- ACID compliance
- Soporte JSON nativo
- Excelente para an√°lisis
- Escalabilidad vertical y horizontal

**Contras:**
- M√°s complejo de configurar
- Mayor overhead para datos simples

#### 2. MongoDB
**Pros:**
- Flexible schema
- Bueno para datos no estructurados
- Escalabilidad horizontal

**Contras:**
- No ACID por defecto
- Menos maduro para transacciones financieras

#### 3. SQLite + PostgreSQL
**Pros:**
- SQLite para desarrollo y testing
- PostgreSQL para producci√≥n
- Transici√≥n suave

**Contras:**
- Diferencias entre entornos
- Migraci√≥n requerida

### Decisi√≥n
**Elegimos SQLite + PostgreSQL** (h√≠brido).

### Justificaci√≥n
1. **Desarrollo**: SQLite para desarrollo local y testing
2. **Producci√≥n**: PostgreSQL para producci√≥n
3. **Transici√≥n**: Migraci√≥n gradual sin cambios de c√≥digo
4. **Flexibilidad**: Misma interfaz SQL para ambos

### Implementaci√≥n
```python
# Configuraci√≥n de base de datos
class DatabaseConfig:
    def __init__(self):
        self.sqlite_path = "trading_bot.db"  # Desarrollo
        self.postgres_url = "postgresql://..."  # Producci√≥n
        self.use_postgres = os.getenv("USE_POSTGRES", "false").lower() == "true"

# Pool de conexiones
class DatabaseConnectionPool:
    def __init__(self, config: DatabaseConfig):
        if config.use_postgres:
            self.engine = create_engine(config.postgres_url)
        else:
            self.engine = create_engine(f"sqlite:///{config.sqlite_path}")
```

### Optimizaciones
1. **√çndices**: √çndices optimizados para queries de trading
2. **Connection Pooling**: Pool de conexiones para performance
3. **Read Replicas**: Para an√°lisis y reportes
4. **Partitioning**: Por fecha para datos hist√≥ricos

---

## ADR-004: Sistema de Cache con Redis

**Fecha**: 2024-01-15  
**Estado**: Aceptado  
**Decisor**: Equipo de Performance  

### Contexto
Necesitamos un sistema de cache para:
- Datos de mercado frecuentemente accedidos
- Resultados de an√°lisis t√©cnico
- Sesiones de usuario
- Reducir latencia de APIs

### Opciones Consideradas

#### 1. Cache en Memoria (Python dict)
**Pros:**
- Muy r√°pido
- Sin dependencias externas
- Simple de implementar

**Contras:**
- No persistente
- No escalable entre procesos
- Memoria limitada

#### 2. Memcached
**Pros:**
- Simple y r√°pido
- Maduro y estable
- Bajo overhead

**Contras:**
- Solo strings
- Sin persistencia
- Funcionalidad limitada

#### 3. Redis
**Pros:**
- Estructuras de datos ricas
- Persistencia opcional
- Pub/Sub para real-time
- Clustering y replicaci√≥n

**Contras:**
- M√°s complejo
- Mayor uso de memoria

### Decisi√≥n
**Elegimos Redis** como sistema de cache.

### Justificaci√≥n
1. **Funcionalidad**: Estructuras de datos ricas (sets, lists, hashes)
2. **Persistencia**: Datos importantes no se pierden
3. **Real-time**: Pub/Sub para notificaciones
4. **Escalabilidad**: Clustering para futuro crecimiento

### Implementaci√≥n
```python
class RedisCacheManager:
    def __init__(self):
        self.redis = redis.Redis(
            host='localhost',
            port=6379,
            db=0,
            decode_responses=False
        )
    
    def cache_market_data(self, symbol: str, data: dict, ttl: int = 300):
        key = f"market_data:{symbol}"
        self.redis.setex(key, ttl, json.dumps(data))
    
    def get_market_data(self, symbol: str) -> Optional[dict]:
        key = f"market_data:{symbol}"
        data = self.redis.get(key)
        return json.loads(data) if data else None
```

### Estrategias de Cache
1. **Write-Through**: Escribir a DB y cache simult√°neamente
2. **Cache-Aside**: Aplicaci√≥n maneja cache expl√≠citamente
3. **TTL Din√°mico**: TTL basado en volatilidad del mercado
4. **Invalidaci√≥n**: Invalidar cache cuando datos cambian

---

## ADR-005: Arquitectura de An√°lisis T√©cnico

**Fecha**: 2024-01-15  
**Estado**: Aceptado  
**Decisor**: Equipo de Trading  

### Contexto
Necesitamos dise√±ar una arquitectura para an√°lisis t√©cnico que soporte:
- M√∫ltiples estrategias (S/R, ICT, Fibonacci, etc.)
- An√°lisis en tiempo real
- Caching de resultados
- Extensibilidad para nuevas estrategias

### Opciones Consideradas

#### 1. Monol√≠tico
**Pros:**
- Simple de implementar
- F√°cil debugging
- Performance √≥ptimo

**Contras:**
- Acoplamiento alto
- Dif√≠cil de extender
- Testing complejo

#### 2. Strategy Pattern
**Pros:**
- F√°cil agregar nuevas estrategias
- Desacoplamiento
- Testing individual

**Contras:**
- Complejidad inicial
- Overhead de abstracci√≥n

#### 3. Plugin Architecture
**Pros:**
- M√°xima flexibilidad
- Hot-swapping de estrategias
- Separaci√≥n completa

**Contras:**
- Complejidad alta
- Overhead significativo

### Decisi√≥n
**Elegimos Strategy Pattern** con interfaces bien definidas.

### Justificaci√≥n
1. **Extensibilidad**: F√°cil agregar nuevas estrategias
2. **Testing**: Cada estrategia se puede testear independientemente
3. **Mantenibilidad**: C√≥digo m√°s limpio y organizado
4. **Performance**: Overhead m√≠nimo

### Implementaci√≥n
```python
from abc import ABC, abstractmethod

class TechnicalAnalyzer(ABC):
    @abstractmethod
    def analyze(self, symbol: str, data: pd.DataFrame) -> Dict[str, Any]:
        pass
    
    @abstractmethod
    def get_signals(self, analysis_result: Dict) -> List[TradingSignal]:
        pass

class SupportResistanceAnalyzer(TechnicalAnalyzer):
    def analyze(self, symbol: str, data: pd.DataFrame) -> Dict[str, Any]:
        # Implementaci√≥n espec√≠fica
        return {
            'support_levels': self._find_support_levels(data),
            'resistance_levels': self._find_resistance_levels(data),
            'confidence': self._calculate_confidence(data)
        }

class AnalysisEngine:
    def __init__(self):
        self.analyzers = {
            'support_resistance': SupportResistanceAnalyzer(),
            'ict': ICTAnalyzer(),
            'fibonacci': FibonacciAnalyzer()
        }
    
    def run_analysis(self, symbol: str, strategies: List[str]) -> Dict[str, Any]:
        results = {}
        for strategy in strategies:
            if strategy in self.analyzers:
                results[strategy] = self.analyzers[strategy].analyze(symbol, data)
        return results
```

### Beneficios
1. **Modularidad**: Cada estrategia es independiente
2. **Reutilizaci√≥n**: Analizadores se pueden usar en diferentes contextos
3. **Testing**: Tests unitarios para cada estrategia
4. **Performance**: An√°lisis paralelo de m√∫ltiples estrategias

---

## ADR-006: Integraci√≥n de IA con Ollama

**Fecha**: 2024-01-15  
**Estado**: Aceptado  
**Decisor**: Equipo de IA  

### Contexto
Necesitamos integrar IA para:
- An√°lisis de sentimiento del mercado
- Validaci√≥n de se√±ales de trading
- Recomendaciones autom√°ticas
- Procesamiento de lenguaje natural

### Opciones Consideradas

#### 1. APIs Cloud (OpenAI, Anthropic)
**Pros:**
- Modelos de √∫ltima generaci√≥n
- Sin infraestructura propia
- Actualizaciones autom√°ticas

**Contras:**
- Costo por uso
- Dependencia externa
- Latencia de red
- Privacidad de datos

#### 2. Modelos Locales (Ollama)
**Pros:**
- Control total de datos
- Sin costos por uso
- Baja latencia
- Privacidad completa

**Contras:**
- Requiere hardware potente
- Mantenimiento de infraestructura
- Modelos menos actualizados

#### 3. H√≠brido
**Pros:**
- Mejor de ambos mundos
- Fallback autom√°tico
- Flexibilidad

**Contras:**
- Complejidad de implementaci√≥n
- Costos mixtos

### Decisi√≥n
**Elegimos Ollama** con modelo GPT OSS 120B Turbo.

### Justificaci√≥n
1. **Privacidad**: Datos de trading sensibles
2. **Latencia**: An√°lisis en tiempo real
3. **Costo**: Sin costos por uso
4. **Control**: Control total del sistema

### Implementaci√≥n
```python
import ollama

class OllamaTradingAI:
    def __init__(self, model_name: str = "gpt-oss-120b-turbo"):
        self.model_name = model_name
        self.client = ollama.Client()
    
    async def analyze_market_sentiment(self, market_data: Dict) -> Dict[str, Any]:
        prompt = f"""
        Analiza el sentimiento del mercado para {market_data['symbol']}:
        - Precio: ${market_data['price']}
        - Volumen: {market_data['volume']}
        - RSI: {market_data['rsi']}
        - MACD: {market_data['macd']}
        
        Proporciona:
        1. Sentimiento (bullish/bearish/neutral)
        2. Confianza (0-1)
        3. Razones
        4. Recomendaciones
        """
        
        response = await self.client.chat(
            model=self.model_name,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return self._parse_response(response['message']['content'])
    
    def _parse_response(self, response: str) -> Dict[str, Any]:
        # Parsear respuesta estructurada
        # Implementar parsing robusto
        pass
```

### Configuraci√≥n de Hardware
- **RAM**: M√≠nimo 32GB (recomendado 64GB)
- **GPU**: RTX 4090 o superior (opcional)
- **CPU**: 16+ cores
- **Storage**: SSD NVMe para modelos

---

## ADR-007: Gesti√≥n de Riesgo Multi-Nivel

**Fecha**: 2024-01-15  
**Estado**: Aceptado  
**Decisor**: Equipo de Risk Management  

### Contexto
Necesitamos un sistema de gesti√≥n de riesgo que soporte:
- M√∫ltiples niveles de riesgo
- C√°lculo autom√°tico de posici√≥n
- Protecci√≥n de capital
- Compliance regulatorio

### Opciones Consideradas

#### 1. Sistema Simple
**Pros:**
- F√°cil de implementar
- Bajo overhead
- Comprensible

**Contras:**
- Limitado en funcionalidad
- No escalable
- Menos flexible

#### 2. Sistema Complejo
**Pros:**
- M√°xima funcionalidad
- Muy flexible
- Escalable

**Contras:**
- Complejidad alta
- Dif√≠cil de mantener
- Overhead significativo

#### 3. Sistema Modular
**Pros:**
- Balance entre simplicidad y funcionalidad
- F√°cil de extender
- Mantenible

**Contras:**
- Dise√±o inicial m√°s complejo

### Decisi√≥n
**Elegimos Sistema Modular** con 3 niveles de riesgo.

### Justificaci√≥n
1. **Usuarios diversos**: Diferentes tolerancias al riesgo
2. **Flexibilidad**: F√°cil agregar nuevos niveles
3. **Mantenibilidad**: C√≥digo organizado y testeable

### Implementaci√≥n
```python
from enum import Enum
from dataclasses import dataclass

class RiskLevel(Enum):
    CONSERVATIVE = "conservative"
    RISKY = "risky"
    TURBO = "turbo"

@dataclass
class PositionSizing:
    max_leverage: float
    position_size_percent: float
    stop_loss_percent: float
    take_profit_percent: float
    
    @classmethod
    def conservative(cls):
        return cls(
            max_leverage=2.0,
            position_size_percent=0.02,
            stop_loss_percent=0.01,
            take_profit_percent=0.02
        )
    
    @classmethod
    def risky(cls):
        return cls(
            max_leverage=5.0,
            position_size_percent=0.05,
            stop_loss_percent=0.015,
            take_profit_percent=0.03
        )
    
    @classmethod
    def turbo(cls):
        return cls(
            max_leverage=10.0,
            position_size_percent=0.10,
            stop_loss_percent=0.02,
            take_profit_percent=0.05
        )

class RiskManager:
    def __init__(self):
        self.current_risk_level = RiskLevel.CONSERVATIVE
        self.position_sizing = PositionSizing.conservative()
    
    def set_risk_level(self, risk_level: RiskLevel):
        self.current_risk_level = risk_level
        if risk_level == RiskLevel.CONSERVATIVE:
            self.position_sizing = PositionSizing.conservative()
        elif risk_level == RiskLevel.RISKY:
            self.position_sizing = PositionSizing.risky()
        elif risk_level == RiskLevel.TURBO:
            self.position_sizing = PositionSizing.turbo()
    
    def calculate_position_size(self, account_balance: float, symbol: str) -> float:
        max_position_value = account_balance * self.position_sizing.position_size_percent
        # L√≥gica adicional de c√°lculo
        return max_position_value
```

### Niveles de Riesgo
1. **Conservador**: 1-2x leverage, 2% por trade
2. **Arriesgado**: 3-5x leverage, 5% por trade
3. **Turbo**: 6-10x leverage, 10% por trade

---

## ADR-008: Sistema de Monitoreo y Alertas

**Fecha**: 2024-01-15  
**Estado**: Aceptado  
**Decisor**: Equipo de DevOps  

### Contexto
Necesitamos un sistema de monitoreo que cubra:
- M√©tricas del sistema
- M√©tricas de la aplicaci√≥n
- M√©tricas de trading
- Alertas autom√°ticas

### Opciones Consideradas

#### 1. Sistema Simple (Logs + Scripts)
**Pros:**
- F√°cil de implementar
- Bajo costo
- Control total

**Contras:**
- Funcionalidad limitada
- Escalabilidad pobre
- Mantenimiento manual

#### 2. Prometheus + Grafana
**Pros:**
- Est√°ndar de la industria
- Muy flexible
- Gran ecosistema

**Contras:**
- Curva de aprendizaje
- Complejidad operacional

#### 3. Soluciones Cloud (DataDog, New Relic)
**Pros:**
- Funcionalidad completa
- Sin infraestructura
- Soporte profesional

**Contras:**
- Costo alto
- Dependencia externa
- Privacidad de datos

### Decisi√≥n
**Elegimos Prometheus + Grafana** con alertas personalizadas.

### Justificaci√≥n
1. **Open Source**: Sin costos de licencia
2. **Flexibilidad**: M√©tricas personalizadas
3. **Escalabilidad**: Crece con el sistema
4. **Est√°ndar**: Conocimiento transferible

### Implementaci√≥n
```python
from prometheus_client import Counter, Histogram, Gauge

class PrometheusMetrics:
    def __init__(self):
        # M√©tricas del sistema
        self.system_cpu = Gauge('system_cpu_percent', 'CPU usage')
        self.system_memory = Gauge('system_memory_percent', 'Memory usage')
        
        # M√©tricas de trading
        self.trading_orders = Counter('trading_orders_total', 'Total orders', ['symbol', 'side'])
        self.trading_pnl = Gauge('trading_pnl_total', 'Total PnL', ['symbol'])
        
        # M√©tricas de autopilot
        self.autopilot_signals = Counter('autopilot_signals_total', 'Total signals', ['strategy'])
        self.autopilot_confidence = Gauge('autopilot_confidence_avg', 'Average confidence', ['strategy'])
    
    def update_system_metrics(self, cpu_percent: float, memory_percent: float):
        self.system_cpu.set(cpu_percent)
        self.system_memory.set(memory_percent)
    
    def record_trading_order(self, symbol: str, side: str):
        self.trading_orders.labels(symbol=symbol, side=side).inc()

class AlertManager:
    def __init__(self):
        self.thresholds = {
            'cpu_percent': {'warning': 80, 'critical': 95},
            'memory_percent': {'warning': 85, 'critical': 95},
            'error_rate': {'warning': 0.05, 'critical': 0.1}
        }
    
    def check_thresholds(self, metrics: Dict[str, float]):
        for metric, value in metrics.items():
            if metric in self.thresholds:
                thresholds = self.thresholds[metric]
                if value > thresholds['critical']:
                    self._trigger_critical_alert(metric, value)
                elif value > thresholds['warning']:
                    self._trigger_warning_alert(metric, value)
```

### M√©tricas Clave
1. **Sistema**: CPU, memoria, disco, red
2. **Aplicaci√≥n**: Requests/sec, latencia, errores
3. **Trading**: √ìrdenes, PnL, drawdown
4. **Autopilot**: Se√±ales, confianza, rendimiento

---

## ADR-009: Estrategia de Testing

**Fecha**: 2024-01-15  
**Estado**: Aceptado  
**Decisor**: Equipo de QA  

### Contexto
Necesitamos una estrategia de testing que asegure:
- Calidad del c√≥digo
- Confiabilidad del sistema
- Cobertura adecuada
- Testing automatizado

### Opciones Consideradas

#### 1. Testing Manual
**Pros:**
- F√°cil de implementar
- Bajo costo inicial
- Flexible

**Contras:**
- No escalable
- Propenso a errores
- Tiempo consumidor

#### 2. Testing Automatizado B√°sico
**Pros:**
- Consistente
- R√°pido
- Repetible

**Contras:**
- Inversi√≥n inicial
- Mantenimiento
- Cobertura limitada

#### 3. Testing Comprehensivo
**Pros:**
- M√°xima cobertura
- Alta confiabilidad
- Detecci√≥n temprana de bugs

**Contras:**
- Alto costo
- Complejidad
- Tiempo de desarrollo

### Decisi√≥n
**Elegimos Testing Comprehensivo** con m√∫ltiples niveles.

### Justificaci√≥n
1. **Sistema cr√≠tico**: Trading con dinero real
2. **Complejidad**: M√∫ltiples componentes integrados
3. **Confianza**: Usuarios conf√≠an su capital
4. **ROI**: Bugs son muy costosos

### Implementaci√≥n
```python
# Estructura de testing
tests/
‚îú‚îÄ‚îÄ unit/                    # Tests unitarios
‚îÇ   ‚îú‚îÄ‚îÄ test_trading.py
‚îÇ   ‚îú‚îÄ‚îÄ test_analysis.py
‚îÇ   ‚îî‚îÄ‚îÄ test_risk.py
‚îú‚îÄ‚îÄ integration/             # Tests de integraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îú‚îÄ‚îÄ test_database.py
‚îÇ   ‚îî‚îÄ‚îÄ test_redis.py
‚îú‚îÄ‚îÄ e2e/                     # Tests end-to-end
‚îÇ   ‚îú‚îÄ‚îÄ test_trading_flow.py
‚îÇ   ‚îî‚îÄ‚îÄ test_autopilot.py
‚îî‚îÄ‚îÄ performance/             # Tests de performance
    ‚îú‚îÄ‚îÄ test_load.py
    ‚îî‚îÄ‚îÄ test_stress.py

# Configuraci√≥n pytest
pytest.ini:
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = --cov=gbsb --cov-report=html --cov-report=xml
markers =
    unit: Unit tests
    integration: Integration tests
    e2e: End-to-end tests
    slow: Slow tests
```

### Tipos de Testing
1. **Unit Tests**: Componentes individuales
2. **Integration Tests**: Interacciones entre componentes
3. **E2E Tests**: Flujos completos de usuario
4. **Performance Tests**: Carga y stress
5. **Security Tests**: Vulnerabilidades

### Cobertura Objetivo
- **Unit Tests**: 90%+
- **Integration Tests**: 80%+
- **E2E Tests**: 70%+
- **Overall**: 85%+

---

## ADR-010: Pipeline de CI/CD

**Fecha**: 2024-01-15  
**Estado**: Aceptado  
**Decisor**: Equipo de DevOps  

### Contexto
Necesitamos un pipeline de CI/CD que:
- Automatice testing
- Facilite deployment
- Asegure calidad
- Reduzca tiempo de entrega

### Opciones Consideradas

#### 1. Scripts Manuales
**Pros:**
- Control total
- F√°cil de entender
- Sin dependencias

**Contras:**
- Propenso a errores
- No escalable
- Tiempo consumidor

#### 2. GitHub Actions
**Pros:**
- Integrado con GitHub
- F√°cil configuraci√≥n
- Gran ecosistema
- Sin costo para repos p√∫blicos

**Contras:**
- Limitado a GitHub
- Menos flexible que Jenkins

#### 3. Jenkins
**Pros:**
- Muy flexible
- Gran ecosistema
- Control total

**Contras:**
- Complejo de configurar
- Requiere infraestructura
- Mantenimiento

### Decisi√≥n
**Elegimos GitHub Actions** como pipeline principal.

### Justificaci√≥n
1. **Integraci√≥n**: Repositorio en GitHub
2. **Simplicidad**: Configuraci√≥n f√°cil
3. **Costo**: Gratuito para repos p√∫blicos
4. **Ecosistema**: Marketplace de acciones

### Implementaci√≥n
```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.10, 3.11, 3.12]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r tests/requirements-test.txt
    
    - name: Run tests
      run: |
        pytest tests/ --cov=gbsb --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
  
  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Run security scan
      run: |
        pip install bandit safety
        bandit -r gbsb/ scripts/
        safety check
  
  deploy:
    needs: [test, security]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to production
      run: |
        # Comandos de deployment
        echo "Deploying to production..."
```

### Pipeline Stages
1. **Linting**: Code quality checks
2. **Testing**: Unit, integration, e2e tests
3. **Security**: Vulnerability scanning
4. **Build**: Docker image creation
5. **Deploy**: Staging and production
6. **Monitor**: Health checks post-deployment

### Environments
- **Development**: Auto-deploy en push a develop
- **Staging**: Auto-deploy en push a main
- **Production**: Manual approval required

---

## üìù Resumen de Decisiones

| ADR | Decisi√≥n | Impacto | Estado |
|-----|----------|---------|--------|
| 001 | FastAPI | Alto | ‚úÖ Implementado |
| 002 | Monolito Modular | Alto | ‚úÖ Implementado |
| 003 | SQLite + PostgreSQL | Medio | ‚úÖ Implementado |
| 004 | Redis | Medio | ‚úÖ Implementado |
| 005 | Strategy Pattern | Medio | ‚úÖ Implementado |
| 006 | Ollama | Alto | ‚úÖ Implementado |
| 007 | Risk Multi-Level | Alto | ‚úÖ Implementado |
| 008 | Prometheus + Grafana | Medio | ‚úÖ Implementado |
| 009 | Testing Comprehensivo | Alto | ‚úÖ Implementado |
| 010 | GitHub Actions | Medio | ‚úÖ Implementado |

## üîÑ Revisi√≥n y Actualizaci√≥n

Los ADRs deben ser revisados peri√≥dicamente:
- **Revisi√≥n trimestral**: Evaluar decisiones implementadas
- **Actualizaci√≥n**: Cuando cambien requisitos o tecnolog√≠as
- **Archivo**: Mantener historial de cambios

---

*√öltima actualizaci√≥n: 2024-01-15*



